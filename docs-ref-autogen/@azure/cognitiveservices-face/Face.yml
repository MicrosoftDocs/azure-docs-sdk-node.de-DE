### YamlMime:UniversalReference
items:
  - uid: '@azure/cognitiveservices-face.Face'
    name: Face
    fullName: Face
    children:
      - '@azure/cognitiveservices-face.Face.detectWithStream_2'
      - '@azure/cognitiveservices-face.Face.detectWithStream'
      - '@azure/cognitiveservices-face.Face.detectWithStream_1'
      - '@azure/cognitiveservices-face.Face.detectWithUrl_2'
      - '@azure/cognitiveservices-face.Face.detectWithUrl'
      - '@azure/cognitiveservices-face.Face.detectWithUrl_1'
      - '@azure/cognitiveservices-face.Face.constructor'
      - '@azure/cognitiveservices-face.Face.findSimilar_2'
      - '@azure/cognitiveservices-face.Face.findSimilar'
      - '@azure/cognitiveservices-face.Face.findSimilar_1'
      - '@azure/cognitiveservices-face.Face.group'
      - '@azure/cognitiveservices-face.Face.group_2'
      - '@azure/cognitiveservices-face.Face.group_1'
      - '@azure/cognitiveservices-face.Face.identify_2'
      - '@azure/cognitiveservices-face.Face.identify'
      - '@azure/cognitiveservices-face.Face.identify_1'
      - '@azure/cognitiveservices-face.Face.verifyFaceToFace'
      - '@azure/cognitiveservices-face.Face.verifyFaceToFace_2'
      - '@azure/cognitiveservices-face.Face.verifyFaceToFace_1'
      - '@azure/cognitiveservices-face.Face.verifyFaceToPerson_2'
      - '@azure/cognitiveservices-face.Face.verifyFaceToPerson'
      - '@azure/cognitiveservices-face.Face.verifyFaceToPerson_1'
    langs:
      - typeScript
    type: class
    summary: 'Klasse, die ein Gesicht darstellt.'
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.detectWithStream_2'
    name: 'detectWithStream(msRest.HttpRequestBody, FaceDetectWithStreamOptionalParams, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function detectWithStream(image: msRest.HttpRequestBody, options: FaceDetectWithStreamOptionalParams, callback: ServiceCallback<DetectedFace[]>)'
      parameters:
        - id: image
          type:
            - msRest.HttpRequestBody
          description: Ein Bild-Stream.
        - id: options
          type:
            - '@azure/cognitiveservices-face.FaceDetectWithStreamOptionalParams'
          description: Die optionalen Parameter
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.DetectedFace[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceDetectWithStreamResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.detectWithStream'
    name: 'detectWithStream(msRest.HttpRequestBody, Models.FaceDetectWithStreamOptionalParams)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Hiermit werden menschliche Gesichter in einem Bild erkannt und Rechtecke für die Gesichter sowie optional faceIds, Sehenswürdigkeiten und Attribute zurückgegeben.<br />
      * Kein Bild gespeichert werden. Nur das extrahierte gesichtserkennungs-Feature wird auf Server gespeichert werden. Die FaceId ist ein Bezeichner, der gesichtserkennungs-Funktion und verwendet werden, [auftreten – identifizieren](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239), [konfrontiert: Überprüfen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a), und [Gesichtserkennung
      - Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237) zu finden.
      Die Funktionen aus gespeicherten Gesicht läuft und 24 Stunden nach dem Aufruf der ursprünglichen Erkennung gelöscht werden.
      * Optionale Parameter umfassen FaceId Orientierungspunkte und Attribute. Attribute gehören Alter, Geschlecht, HeadPose, Lächeln, FacialHair, Brille, Emotionen, Haare, Zusammensetzung, verdecken, Zubehör, Weichzeichner, Offenlegung und Rauschen. Einige der Ergebnisse zurückgegeben, die auf bestimmte Attribute äußerst präzise möglicherweise nicht.
      * JPEG, PNG, GIF (der erste Frame) und BMP-Format werden unterstützt. Die zulässige Dateigröße liegt zwischen 1KB und 6MB.
      * Für ein Bild können bis zu 100 Gesichter zurückgegeben werden. Gesichter werden nach Gesicht Rechteck Größe von großen auf einen kleinen geordnet.
      * Um optimale Ergebnisse beim Abfragen von [auftreten – identifizieren](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239), [konfrontiert: Überprüfen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a), und [Gesichtserkennung
      - Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237) ("ReturnFaceId" ist "true") suchen, verwenden Sie Gesichter, die: Frontale, löschen, und mit einer Mindestgröße von 200 x 200 Pixel (100 Pixel zwischen Augen).
      * Die minimale erkennbare gesichtserkennungs-Größe ist 36 x 36 Pixel in einem Bild 1920 x 1080 Pixel nicht überschreiten.
      Bilder mit Dimensionen, die höher ist als 1920 x 1080 Pixel benötigen proportional minimale Gesicht vergrößern.
      * Verschiedene "DetectionModel'-Werte können angegeben werden. Zum verwenden und die von anderen erkennungsmodelle vergleichen können, finden Sie in [wie ein Modell zur Erkennung angegeben.](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
      | Modell | Empfohlene Verwendung-case(s) |
      | ---------- | -------- |
      | 'detection_01': | Das Standardmodell für die Erkennung für [Gesicht-
      Detect](/docs/Services/563879b61984550e40cbbe8d/Operations/563879b61984550f30395236). Wird für die in der Nähe von frontal angezeigten Gesichtern Erkennung empfohlen. Für Szenarien mit außergewöhnlich große Spitze (kopfpose) Gesichtern, okkludierte Gesichter oder falsche bildausrichtung werden die Gesichter in solchen Fällen möglicherweise nicht erkannt. | | 'detection_02': | 2019 veröffentlicht Modells zur Erkennung kann mit verbesserter Genauigkeit vor allem auf klein ","-Seite "und" verschwommenen Gesichter. |
      * Verschiedene "RecognitionModel'-Werte werden bereitgestellt. Wenn weitere Vorgänge stellen Sie sicher, identifizieren, wie das werden Suchen von ähnlichen benötigt, geben Sie das Modell zur Erkennung mit 'RecognitionModel'-Parameter. Der Standardwert für 'RecognitionModel' ist "recognition_01", wenn aktuelle Modell explizit Geben Sie benötigt werden, das Modell benötigen Sie in diesem Parameter. Nachdem Sie angegeben haben, werden die erkannten FaceIds der angegebenen anerkennungsmodell zugeordnet werden. Weitere Informationen finden Sie [ein anerkennungsmodell angeben](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
      | Modell | Empfohlene Verwendung-case(s) |
      | ---------- | -------- |
      | 'recognition_01': | Das Standardmodell für die Erkennung für [Gesicht-
      Detect](/docs/Services/563879b61984550e40cbbe8d/Operations/563879b61984550f30395236). Alle diese FaceIds vor 2019 März erstellt wurden, werden mit diesem Modell zur Erkennung Haftend. | | 'recognition_02': | Der Modell zur Erkennung im 2019 März veröffentlicht wurde. "recognition_02" wird empfohlen, da die gesamtgenauigkeit im Vergleich zu 'recognition_01' verbessert wird. |
    syntax:
      content: 'function detectWithStream(image: msRest.HttpRequestBody, options?: Models.FaceDetectWithStreamOptionalParams)'
      parameters:
        - id: image
          type:
            - msRest.HttpRequestBody
          description: Ein Bild-Stream.
        - id: options
          type:
            - Models.FaceDetectWithStreamOptionalParams
          description: ''
          optional: true
      return:
        type:
          - Promise<Models.FaceDetectWithStreamResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.detectWithStream_1'
    name: 'detectWithStream(msRest.HttpRequestBody, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function detectWithStream(image: msRest.HttpRequestBody, callback: ServiceCallback<DetectedFace[]>)'
      parameters:
        - id: image
          type:
            - msRest.HttpRequestBody
          description: Ein Bild-Stream.
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.DetectedFace[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceDetectWithStreamResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.detectWithUrl_2'
    name: 'detectWithUrl(string, FaceDetectWithUrlOptionalParams, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function detectWithUrl(url: string, options: FaceDetectWithUrlOptionalParams, callback: ServiceCallback<DetectedFace[]>)'
      parameters:
        - id: url
          type:
            - string
          description: Öffentlich erreichbar URL eines Bilds
        - id: options
          type:
            - '@azure/cognitiveservices-face.FaceDetectWithUrlOptionalParams'
          description: Die optionalen Parameter
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.DetectedFace[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceDetectWithUrlResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.detectWithUrl'
    name: 'detectWithUrl(string, Models.FaceDetectWithUrlOptionalParams)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Hiermit werden menschliche Gesichter in einem Bild erkannt und Rechtecke für die Gesichter sowie optional faceIds, Sehenswürdigkeiten und Attribute zurückgegeben.<br />
      * Kein Bild gespeichert werden. Nur das extrahierte gesichtserkennungs-Feature wird auf Server gespeichert werden. Die FaceId ist ein Bezeichner, der gesichtserkennungs-Funktion und verwendet werden, [auftreten – identifizieren](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239), [konfrontiert: Überprüfen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a), und [Gesichtserkennung
      - Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237) zu finden.
      Die Funktionen aus gespeicherten Gesicht läuft und 24 Stunden nach dem Aufruf der ursprünglichen Erkennung gelöscht werden.
      * Optionale Parameter umfassen FaceId Orientierungspunkte und Attribute. Attribute gehören Alter, Geschlecht, HeadPose, Lächeln, FacialHair, Brille, Emotionen, Haare, Zusammensetzung, verdecken, Zubehör, Weichzeichner, Offenlegung und Rauschen. Einige der Ergebnisse zurückgegeben, die auf bestimmte Attribute äußerst präzise möglicherweise nicht.
      * JPEG, PNG, GIF (der erste Frame) und BMP-Format werden unterstützt. Die zulässige Dateigröße liegt zwischen 1KB und 6MB.
      * Für ein Bild können bis zu 100 Gesichter zurückgegeben werden. Gesichter werden nach Gesicht Rechteck Größe von großen auf einen kleinen geordnet.
      * Um optimale Ergebnisse beim Abfragen von [auftreten – identifizieren](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239), [konfrontiert: Überprüfen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a), und [Gesichtserkennung
      - Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237) ("ReturnFaceId" ist "true") suchen, verwenden Sie Gesichter, die: Frontale, löschen, und mit einer Mindestgröße von 200 x 200 Pixel (100 Pixel zwischen Augen).
      * Die minimale erkennbare gesichtserkennungs-Größe ist 36 x 36 Pixel in einem Bild 1920 x 1080 Pixel nicht überschreiten.
      Bilder mit Dimensionen, die höher ist als 1920 x 1080 Pixel benötigen proportional minimale Gesicht vergrößern.
      * Verschiedene "DetectionModel'-Werte können angegeben werden. Zum verwenden und die von anderen erkennungsmodelle vergleichen können, finden Sie in [wie ein Modell zur Erkennung angegeben.](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
      | Modell | Empfohlene Verwendung-case(s) |
      | ---------- | -------- |
      | 'detection_01': | Das Standardmodell für die Erkennung für [Gesicht-
      Detect](/docs/Services/563879b61984550e40cbbe8d/Operations/563879b61984550f30395236). Wird für die in der Nähe von frontal angezeigten Gesichtern Erkennung empfohlen. Für Szenarien mit außergewöhnlich große Spitze (kopfpose) Gesichtern, okkludierte Gesichter oder falsche bildausrichtung werden die Gesichter in solchen Fällen möglicherweise nicht erkannt. | | 'detection_02': | 2019 veröffentlicht Modells zur Erkennung kann mit verbesserter Genauigkeit vor allem auf klein ","-Seite "und" verschwommenen Gesichter. |
      * Verschiedene "RecognitionModel'-Werte werden bereitgestellt. Wenn weitere Vorgänge stellen Sie sicher, identifizieren, wie das werden Suchen von ähnlichen benötigt, geben Sie das Modell zur Erkennung mit 'RecognitionModel'-Parameter. Der Standardwert für 'RecognitionModel' ist "recognition_01", wenn aktuelle Modell explizit Geben Sie benötigt werden, das Modell benötigen Sie in diesem Parameter. Nachdem Sie angegeben haben, werden die erkannten FaceIds der angegebenen anerkennungsmodell zugeordnet werden. Weitere Informationen finden Sie [ein anerkennungsmodell angeben](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
      | Modell | Empfohlene Verwendung-case(s) |
      | ---------- | -------- |
      | 'recognition_01': | Das Standardmodell für die Erkennung für [Gesicht-
      Detect](/docs/Services/563879b61984550e40cbbe8d/Operations/563879b61984550f30395236). Alle diese FaceIds vor 2019 März erstellt wurden, werden mit diesem Modell zur Erkennung Haftend. | | 'recognition_02': | Der Modell zur Erkennung im 2019 März veröffentlicht wurde. "recognition_02" wird empfohlen, da die gesamtgenauigkeit im Vergleich zu 'recognition_01' verbessert wird. |
    syntax:
      content: 'function detectWithUrl(url: string, options?: Models.FaceDetectWithUrlOptionalParams)'
      parameters:
        - id: url
          type:
            - string
          description: Öffentlich erreichbar URL eines Bilds
        - id: options
          type:
            - Models.FaceDetectWithUrlOptionalParams
          description: ''
          optional: true
      return:
        type:
          - Promise<Models.FaceDetectWithUrlResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.detectWithUrl_1'
    name: 'detectWithUrl(string, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function detectWithUrl(url: string, callback: ServiceCallback<DetectedFace[]>)'
      parameters:
        - id: url
          type:
            - string
          description: Öffentlich erreichbar URL eines Bilds
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.DetectedFace[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceDetectWithUrlResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.constructor'
    name: Face(FaceClientContext)
    children: []
    type: constructor
    langs:
      - typeScript
    summary: Erstellen Sie eine Fläche.
    syntax:
      content: 'new Face(client: FaceClientContext)'
      parameters:
        - id: client
          type:
            - '@azure/cognitiveservices-face.FaceClientContext'
          description: |
            Verweis auf den Dienstclient.
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.findSimilar_2'
    name: 'findSimilar(string, FaceFindSimilarOptionalParams, ServiceCallback<SimilarFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function findSimilar(faceId: string, options: FaceFindSimilarOptionalParams, callback: ServiceCallback<SimilarFace[]>)'
      parameters:
        - id: faceId
          type:
            - string
          description: 'FaceId des Gesichts Abfrage. Benutzer muss sich das Gesicht aufgerufen: zuerst erhalten eine gültige FaceId zu erkennen. Beachten Sie, dass diese FaceId nicht beibehalten wird und 24 Stunden nach dem Aufruf der Erkennung läuft'
        - id: options
          type:
            - '@azure/cognitiveservices-face.FaceFindSimilarOptionalParams'
          description: Die optionalen Parameter
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.SimilarFace[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceFindSimilarResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.findSimilar'
    name: 'findSimilar(string, Models.FaceFindSimilarOptionalParams)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Hiermit können Sie anhand der faceId des abgefragten Gesichts ähnliche Gesichter aus einem faceId-Array, einer Gesichterliste oder einer umfangreichen Gesichterliste suchen. FaceId-Array enthält die Gesichter von erstellten [konfrontiert: erkennen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236), läuft die 24 Stunden nach der Erstellung. Eine "FaceListId" wird erstellt, indem [FaceList - erstellen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b) mit PersistedFaceIds, die nicht ablaufen. Und ein "LargeFaceListId" wird erstellt, indem [LargeFaceList – erstellen](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc) mit PersistedFaceIds, die auch nicht ablaufen. Abhängig von der Eingabe enthält die zurückgegebene Liste mit ähnlichen Gesichtern FaceIds oder PersistedFaceIds, die Rangfolge richtet sich nach Ähnlichkeit.
      <br/>Suchen von ähnlichen verfügt über zwei funktionierende-Modi, "MatchPerson" und "MatchFace". "MatchPerson" ist der Standardmodus, den versucht wird, finden Sie Gesichter derselben Person wie möglich, mithilfe von internen Schwellenwerten von derselben Person. Es ist hilfreich, einem bekannten Person andere Fotos suchen. Beachten Sie, dass eine leere Liste zurückgegeben wird, wenn keine Gesichter die internen Schwellenwerte überschreiten. "MatchFace" Modus dieselbe Person Schwellenwerte und gibt ähnliche Gesichter trotzdem eingestuft werden ignoriert, sogar die Ähnlichkeit gering. Es kann in den Fällen, z. B. Prominenten Gesichter Suchen verwendet werden.
      <br/>Der Zusammenhang mit der abfragegesicht FaceId RecognitionModel sollte "RecognitionModel" ein, die die FaceId-Zielarray, gesichtserkennungs-Liste oder große Fläche identisch sein.
    syntax:
      content: 'function findSimilar(faceId: string, options?: Models.FaceFindSimilarOptionalParams)'
      parameters:
        - id: faceId
          type:
            - string
          description: 'FaceId des Gesichts Abfrage. Benutzer muss sich das Gesicht aufgerufen: zuerst erhalten eine gültige FaceId zu erkennen. Beachten Sie, dass diese FaceId nicht beibehalten wird und 24 Stunden nach dem Aufruf der Erkennung läuft'
        - id: options
          type:
            - Models.FaceFindSimilarOptionalParams
          description: ''
          optional: true
      return:
        type:
          - Promise<Models.FaceFindSimilarResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.findSimilar_1'
    name: 'findSimilar(string, ServiceCallback<SimilarFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function findSimilar(faceId: string, callback: ServiceCallback<SimilarFace[]>)'
      parameters:
        - id: faceId
          type:
            - string
          description: 'FaceId des Gesichts Abfrage. Benutzer muss sich das Gesicht aufgerufen: zuerst erhalten eine gültige FaceId zu erkennen. Beachten Sie, dass diese FaceId nicht beibehalten wird und 24 Stunden nach dem Aufruf der Erkennung läuft'
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.SimilarFace[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceFindSimilarResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.group'
    name: 'group(string[], msRest.RequestOptionsBase)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Hiermit unterteilen Sie die Gesichter der Kandidaten basierend auf der Gesichterähnlichkeit in Gruppen.<br />
      * Die Ausgabe ist eine oder mehrere Gruppen von separaten Gesicht und einer MessyGroup. Eine Gesichts-Gruppe enthält die Flächen aus, die über ähnliche suchen, häufig von derselben Person. Gruppen werden nach Gruppengröße, d. h. die Anzahl der Gesichter geordnet. Beachten Sie, dass Flächen, die zu einer gleichen Person gehören in mehrere Gruppen im Resultset aufgeteilt werden können.
      * MessyGroup ist eine spezielle gesichtserkennungs-Gruppe, die mit der Flächen aus, die alle ähnliche Entsprechung Gesicht aus der ursprünglichen Gesichter nicht finden können. Die MessyGroup wird nicht im Ergebnis angezeigt, wenn alle Gesichter ihren Entsprechungen gefunden.
      * Group-API benötigt darf höchstens über mindestens 2 Candidate Gesichter und 1000. Wir empfehlen, um zu versuchen [konfrontiert: Überprüfen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a) Wenn Sie nur 2 Candidate Gesichter haben.
      * Der Zusammenhang mit die Abfrage Gesichter FaceIds RecognitionModel sollte identisch sein.
    syntax:
      content: 'function group(faceIds: string[], options?: msRest.RequestOptionsBase)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: Array von möglichen FaceId durch Gesichtserkennung erstellt – zu erkennen. Der Höchstwert beträgt 1.000 Gesichter
        - id: options
          type:
            - msRest.RequestOptionsBase
          description: ''
          optional: true
      return:
        type:
          - Promise<Models.FaceGroupResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.group_2'
    name: 'group(string[], RequestOptionsBase, ServiceCallback<GroupResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function group(faceIds: string[], options: RequestOptionsBase, callback: ServiceCallback<GroupResult>)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: Array von möglichen FaceId durch Gesichtserkennung erstellt – zu erkennen. Der Höchstwert beträgt 1.000 Gesichter
        - id: options
          type:
            - RequestOptionsBase
          description: Die optionalen Parameter
        - id: callback
          type:
            - ServiceCallback<@azure/cognitiveservices-face.GroupResult>
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceGroupResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.group_1'
    name: 'group(string[], ServiceCallback<GroupResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function group(faceIds: string[], callback: ServiceCallback<GroupResult>)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: Array von möglichen FaceId durch Gesichtserkennung erstellt – zu erkennen. Der Höchstwert beträgt 1.000 Gesichter
        - id: callback
          type:
            - ServiceCallback<@azure/cognitiveservices-face.GroupResult>
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceGroupResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.identify_2'
    name: 'identify(string[], FaceIdentifyOptionalParams, ServiceCallback<IdentifyResult[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function identify(faceIds: string[], options: FaceIdentifyOptionalParams, callback: ServiceCallback<IdentifyResult[]>)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: 'Array der Gesichter FaceIds, durch das Gesicht erstellt – zu erkennen. Jede der Flächen werden unabhängig voneinander identifiziert. Die zulässige Anzahl von FaceIds wird zwischen [1, 10].'
        - id: options
          type:
            - '@azure/cognitiveservices-face.FaceIdentifyOptionalParams'
          description: Die optionalen Parameter
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.IdentifyResult[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceIdentifyResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.identify'
    name: 'identify(string[], Models.FaceIdentifyOptionalParams)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      1:n-Identifikationsvorgang zum Ermitteln der besten Ergebnisse für das Gesicht der abgefragten Person aus einer Personengruppe oder umfangreichen Personengruppe.
      <br/> Für jedes Gesicht im Array FaceIds Gesicht zu identifizieren, wird ähnlichkeiten zwischen dem Zifferblatt der Abfrage und alle Gesichter in die Gruppe der Person (angegeben durch PersonGroupId) berechnet oder große Person (angegeben durch LargePersonGroupId) gruppieren und Candidate Person(en) für dieses Gesichts Rangfolge zurück durch die Ähnlichkeit Zuverlässigkeit. Die Gruppe der Gruppe bzw. großen Person Person sollte trainiert werden, um es für die Identifikation bereit zu machen. Weitere Informationen im [PersonGroup - Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249) und [LargePersonGroup – Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).
      <br/>
      Anmerkungen:<br />
      * Der Algorithmus ermöglicht, mehr als ein Gesicht unabhängig voneinander auf die gleiche Anforderung identifiziert werden, aber nicht mehr als 10 Gesichter.
      * Jede Person in die Gruppe der Gruppe bzw. großen Person Person kann mehr als ein Gesicht zu sehen, aber nicht mehr als 248 Gesichter aufweisen.
      * Höhere Gesicht Bildqualität bedeutet bessere Identifizierung mit einfacher Genauigkeit. Erwägen Sie die Gesichter von hoher Qualität: frontalansicht, Clear- und Gesicht beträgt 200 x 200 Pixel (100 Pixel zwischen Augen) oder größer.
      * Anzahl der Kandidaten, die zurückgegeben werden, wird durch MaxNumOfCandidatesReturned und ConfidenceThreshold beschränkt. Wenn keine Personen erkannt wird, werden die zurückgegebene Kandidaten ein leeres Array sein.
      * Versuchen Sie es [Gesichtserkennungs - Suchen von ähnlichen](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237) Wenn Sie ähnliche Gesichter aus einer Liste Gesicht Liste bzw. großen gesichtserkennung anstelle einer Gruppe bzw. großen Personengruppe Person suchen müssen.
      * Der Zusammenhang mit die Abfrage Gesichter FaceIds RecognitionModel sollte "RecognitionModel" ein, die die Zielgruppe für die Person oder große Personengruppen identisch sein.
    syntax:
      content: 'function identify(faceIds: string[], options?: Models.FaceIdentifyOptionalParams)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: 'Array der Gesichter FaceIds, durch das Gesicht erstellt – zu erkennen. Jede der Flächen werden unabhängig voneinander identifiziert. Die zulässige Anzahl von FaceIds wird zwischen [1, 10].'
        - id: options
          type:
            - Models.FaceIdentifyOptionalParams
          description: ''
          optional: true
      return:
        type:
          - Promise<Models.FaceIdentifyResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.identify_1'
    name: 'identify(string[], ServiceCallback<IdentifyResult[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function identify(faceIds: string[], callback: ServiceCallback<IdentifyResult[]>)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: 'Array der Gesichter FaceIds, durch das Gesicht erstellt – zu erkennen. Jede der Flächen werden unabhängig voneinander identifiziert. Die zulässige Anzahl von FaceIds wird zwischen [1, 10].'
        - id: callback
          type:
            - 'ServiceCallback<@azure/cognitiveservices-face.IdentifyResult[]>'
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceIdentifyResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.verifyFaceToFace'
    name: 'verifyFaceToFace(string, string, msRest.RequestOptionsBase)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Hiermit überprüfen Sie, ob zwei Gesichter zu derselben Person gehören oder ob je ein Gesicht zu einer Person gehört.
      <br/>
      Anmerkungen:<br />
      * Höhere Gesicht Bildqualität bedeutet bessere Identifizierung mit einfacher Genauigkeit. Erwägen Sie die Gesichter von hoher Qualität: frontalansicht, Clear- und Gesicht beträgt 200 x 200 Pixel (100 Pixel zwischen Augen) oder größer.
      * Stellen Sie sich an Ihr eigenes Urteilsvermögen, für die Szenarien, die zu einer Genauigkeit anfällig sind.
      * Der Zusammenhang mit die Abfrage Gesichter FaceIds RecognitionModel sollte "RecognitionModel" verwendet, die vom Ziel Gesicht, Personengruppen oder große Personengruppen identisch sein.
    syntax:
      content: 'function verifyFaceToFace(faceId1: string, faceId2: string, options?: msRest.RequestOptionsBase)'
      parameters:
        - id: faceId1
          type:
            - string
          description: 'FaceId, der das erste Gesicht stammt Gesicht: erkennen'
        - id: faceId2
          type:
            - string
          description: 'FaceId, der das zweite Gesicht stammt Gesicht: erkennen'
        - id: options
          type:
            - msRest.RequestOptionsBase
          description: ''
          optional: true
      return:
        type:
          - Promise<Models.FaceVerifyFaceToFaceResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.verifyFaceToFace_2'
    name: 'verifyFaceToFace(string, string, RequestOptionsBase, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function verifyFaceToFace(faceId1: string, faceId2: string, options: RequestOptionsBase, callback: ServiceCallback<VerifyResult>)'
      parameters:
        - id: faceId1
          type:
            - string
          description: 'FaceId, der das erste Gesicht stammt Gesicht: erkennen'
        - id: faceId2
          type:
            - string
          description: 'FaceId, der das zweite Gesicht stammt Gesicht: erkennen'
        - id: options
          type:
            - RequestOptionsBase
          description: Die optionalen Parameter
        - id: callback
          type:
            - ServiceCallback<@azure/cognitiveservices-face.VerifyResult>
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceVerifyFaceToFaceResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.verifyFaceToFace_1'
    name: 'verifyFaceToFace(string, string, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function verifyFaceToFace(faceId1: string, faceId2: string, callback: ServiceCallback<VerifyResult>)'
      parameters:
        - id: faceId1
          type:
            - string
          description: 'FaceId, der das erste Gesicht stammt Gesicht: erkennen'
        - id: faceId2
          type:
            - string
          description: 'FaceId, der das zweite Gesicht stammt Gesicht: erkennen'
        - id: callback
          type:
            - ServiceCallback<@azure/cognitiveservices-face.VerifyResult>
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceVerifyFaceToFaceResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.verifyFaceToPerson_2'
    name: 'verifyFaceToPerson(string, string, FaceVerifyFaceToPersonOptionalParams, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function verifyFaceToPerson(faceId: string, personId: string, options: FaceVerifyFaceToPersonOptionalParams, callback: ServiceCallback<VerifyResult>)'
      parameters:
        - id: faceId
          type:
            - string
          description: 'FaceId des Gesichts, stammen von Face: erkennen'
        - id: personId
          type:
            - string
          description: Geben Sie eine bestimmte Person in einer Person oder eine große Personengruppe ein. PersonId in PersonGroup Person erstellt wird – erstellen oder LargePersonGroup Person.
        - id: options
          type:
            - '@azure/cognitiveservices-face.FaceVerifyFaceToPersonOptionalParams'
          description: Die optionalen Parameter
        - id: callback
          type:
            - ServiceCallback<@azure/cognitiveservices-face.VerifyResult>
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceVerifyFaceToPersonResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.verifyFaceToPerson'
    name: 'verifyFaceToPerson(string, string, Models.FaceVerifyFaceToPersonOptionalParams)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Überprüfen Sie, ob die beiden Gesichter einer derselben Person angehören. Vergleicht eine Gesichts-Id mit dem eine Person-Id'
    syntax:
      content: 'function verifyFaceToPerson(faceId: string, personId: string, options?: Models.FaceVerifyFaceToPersonOptionalParams)'
      parameters:
        - id: faceId
          type:
            - string
          description: 'FaceId des Gesichts, stammen von Face: erkennen'
        - id: personId
          type:
            - string
          description: Geben Sie eine bestimmte Person in einer Person oder eine große Personengruppe ein. PersonId in PersonGroup Person erstellt wird – erstellen oder LargePersonGroup Person.
        - id: options
          type:
            - Models.FaceVerifyFaceToPersonOptionalParams
          description: ''
          optional: true
      return:
        type:
          - Promise<Models.FaceVerifyFaceToPersonResponse>
    package: '@azure/cognitiveservices-face'
  - uid: '@azure/cognitiveservices-face.Face.verifyFaceToPerson_1'
    name: 'verifyFaceToPerson(string, string, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function verifyFaceToPerson(faceId: string, personId: string, callback: ServiceCallback<VerifyResult>)'
      parameters:
        - id: faceId
          type:
            - string
          description: 'FaceId des Gesichts, stammen von Face: erkennen'
        - id: personId
          type:
            - string
          description: Geben Sie eine bestimmte Person in einer Person oder eine große Personengruppe ein. PersonId in PersonGroup Person erstellt wird – erstellen oder LargePersonGroup Person.
        - id: callback
          type:
            - ServiceCallback<@azure/cognitiveservices-face.VerifyResult>
          description: |
            Der Rückruf
      return:
        type:
          - Promise<Models.FaceVerifyFaceToPersonResponse>
    package: '@azure/cognitiveservices-face'
references:
  - uid: '@azure/cognitiveservices-face.FaceClientContext'
    name: FaceClientContext
    spec.typeScript:
      - name: FaceClientContext
        fullName: FaceClientContext
        uid: '@azure/cognitiveservices-face.FaceClientContext'
  - uid: 'ServiceCallback<@azure/cognitiveservices-face.DetectedFace[]>'
    name: 'DetectedFace[]>'
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DetectedFace
        fullName: DetectedFace
        uid: '@azure/cognitiveservices-face.DetectedFace'
      - name: '[]>'
        fullName: '[]>'
  - uid: '@azure/cognitiveservices-face.FaceDetectWithStreamOptionalParams'
    name: FaceDetectWithStreamOptionalParams
    spec.typeScript:
      - name: FaceDetectWithStreamOptionalParams
        fullName: FaceDetectWithStreamOptionalParams
        uid: '@azure/cognitiveservices-face.FaceDetectWithStreamOptionalParams'
  - uid: '@azure/cognitiveservices-face.FaceDetectWithUrlOptionalParams'
    name: FaceDetectWithUrlOptionalParams
    spec.typeScript:
      - name: FaceDetectWithUrlOptionalParams
        fullName: FaceDetectWithUrlOptionalParams
        uid: '@azure/cognitiveservices-face.FaceDetectWithUrlOptionalParams'
  - uid: 'ServiceCallback<@azure/cognitiveservices-face.SimilarFace[]>'
    name: 'SimilarFace[]>'
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: SimilarFace
        fullName: SimilarFace
        uid: '@azure/cognitiveservices-face.SimilarFace'
      - name: '[]>'
        fullName: '[]>'
  - uid: '@azure/cognitiveservices-face.FaceFindSimilarOptionalParams'
    name: FaceFindSimilarOptionalParams
    spec.typeScript:
      - name: FaceFindSimilarOptionalParams
        fullName: FaceFindSimilarOptionalParams
        uid: '@azure/cognitiveservices-face.FaceFindSimilarOptionalParams'
  - uid: ServiceCallback<@azure/cognitiveservices-face.GroupResult>
    name: GroupResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: GroupResult
        fullName: GroupResult
        uid: '@azure/cognitiveservices-face.GroupResult'
      - name: '>'
        fullName: '>'
  - uid: 'ServiceCallback<@azure/cognitiveservices-face.IdentifyResult[]>'
    name: 'IdentifyResult[]>'
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: IdentifyResult
        fullName: IdentifyResult
        uid: '@azure/cognitiveservices-face.IdentifyResult'
      - name: '[]>'
        fullName: '[]>'
  - uid: '@azure/cognitiveservices-face.FaceIdentifyOptionalParams'
    name: FaceIdentifyOptionalParams
    spec.typeScript:
      - name: FaceIdentifyOptionalParams
        fullName: FaceIdentifyOptionalParams
        uid: '@azure/cognitiveservices-face.FaceIdentifyOptionalParams'
  - uid: ServiceCallback<@azure/cognitiveservices-face.VerifyResult>
    name: VerifyResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: VerifyResult
        fullName: VerifyResult
        uid: '@azure/cognitiveservices-face.VerifyResult'
      - name: '>'
        fullName: '>'
  - uid: '@azure/cognitiveservices-face.FaceVerifyFaceToPersonOptionalParams'
    name: FaceVerifyFaceToPersonOptionalParams
    spec.typeScript:
      - name: FaceVerifyFaceToPersonOptionalParams
        fullName: FaceVerifyFaceToPersonOptionalParams
        uid: '@azure/cognitiveservices-face.FaceVerifyFaceToPersonOptionalParams'