### YamlMime:UniversalReference
items:
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient
    name: ComputerVisionClient
    fullName: ComputerVisionClient
    children:
      - azure-cognitiveservices-computervision.ComputerVisionClient.addUserAgentInfo
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.constructor
      - azure-cognitiveservices-computervision.ComputerVisionClient.credentials
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getPackageJsonInfo
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequestWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    langs:
      - typeScript
    type: class
    summary: ''
    extends:
      name: ServiceClient
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.addUserAgentInfo
    name: addUserAgentInfo(any)
    children: []
    type: method
    langs:
      - typeScript
    summary: Benutzer-Agent-Header mit benutzerdefinierten Informationen hinzugef√ºgt
    syntax:
      content: 'function addUserAgentInfo(additionalUserAgentInfo: any)'
      parameters:
        - id: additionalUserAgentInfo
          type:
            - any
          description: |
            Informationen, die Benutzer-Agent-Header, die als Zeichenfolge hinzugef√ºgt werden.
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
    name: 'analyzeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
    name: 'analyzeImage(string, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImage(url: string, options: Object, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
    name: 'analyzeImage(string, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
    name: 'analyzeImageByDomain(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der dom√§nenspezifischen, zu erkennen.
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
    name: 'analyzeImageByDomain(string, string, Object, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, options: Object, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
    name: 'analyzeImageByDomain(string, string, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der dom√§nenspezifischen, zu erkennen.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: Object, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
    name: 'analyzeImageByDomainInStream(string, stream.Readable, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
    name: 'analyzeImageByDomainInStreamWithHttpOperationResponse(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der dom√§nenspezifischen, zu erkennen.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
    name: 'analyzeImageByDomainWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines dom√§nenspezifischen Modells. Die Liste dom√§nenspezifischer Modelle, die von der Maschinelles Sehen-API unterst√ºtzt werden, kann √ºber die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende dom√§nenspezifische Modelle: celebrities (Prominente), landmarks (Sehensw√ºrdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der dom√§nenspezifischen, zu erkennen.
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
    name: 'analyzeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
    name: 'analyzeImageInStream(stream.Readable, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
    name: 'analyzeImageInStream(stream.Readable, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
    name: 'analyzeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
    name: 'analyzeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt. In Ihre Anforderung ist ein optionaler Parameter k√∂nnen Sie ausw√§hlen, welche Funktionen zum Zur√ºckgeben vorhanden. Standardm√§√üig werden die Image-Kategorien in der Antwort zur√ºckgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
    name: 'batchReadFile(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden m√ºssen.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
    name: 'batchReadFile(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden m√ºssen.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
    name: 'batchReadFile(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden m√ºssen.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
    name: 'batchReadFileInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enth√§lt die URL, die Sie, f√ºr die "Abrufen Ihrer Lesen der Ergebnisse verwenden m√ºssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
    name: 'batchReadFileInStream(stream.Readable, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enth√§lt die URL, die Sie, f√ºr die "Abrufen Ihrer Lesen der Ergebnisse verwenden m√ºssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
    name: 'batchReadFileInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enth√§lt die URL, die Sie, f√ºr die "Abrufen Ihrer Lesen der Ergebnisse verwenden m√ºssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
    name: 'batchReadFileInStreamWithHttpOperationResponse(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enth√§lt die URL, die Sie, f√ºr die "Abrufen Ihrer Lesen der Ergebnisse verwenden m√ºssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
    name: 'batchReadFileWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen f√ºr textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden m√ºssen.'
    syntax:
      content: 'function batchReadFileWithHttpOperationResponse(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.constructor
    name: 'ComputerVisionClient(ServiceClientCredentials, string, ServiceClientOptions)'
    children: []
    type: constructor
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'new ComputerVisionClient(credentials: ServiceClientCredentials, endpoint: string, options?: ServiceClientOptions)'
      parameters:
        - id: credentials
          type:
            - ServiceClientCredentials
          description: |
            Abonnementanmeldeinformationen, die clientabonnement eindeutig identifiziert.
        - id: endpoint
          type:
            - string
          description: |
            Cognitive Services-Endpunkte unterst√ºtzt.
        - id: options
          type:
            - ServiceClientOptions
          description: ''
          optional: true
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.credentials
    name: credentials
    fullName: credentials
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'credentials: ServiceClientCredentials'
      return:
        type:
          - ServiceClientCredentials
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
    name: 'describeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
    name: 'describeImage(string, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImage(url: string, options: Object, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
    name: 'describeImage(string, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
    name: 'describeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
    name: 'describeImageInStream(stream.Readable, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
    name: 'describeImageInStream(stream.Readable, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
    name: 'describeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
    name: 'describeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollst√§ndigen S√§tzen in verst√§ndlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zur√ºckgegeben werden. F√ºr jedes Bild k√∂nnen mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverl√§ssigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
    name: 'detectObjects(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjects(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
    name: 'detectObjects(string, Object, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjects(url: string, options: Object, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
    name: 'detectObjects(string, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjects(url: string, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
    name: 'detectObjectsInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
    name: 'detectObjectsInStream(stream.Readable, Object, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, options: Object, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
    name: 'detectObjectsInStream(stream.Readable, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
    name: 'detectObjectsInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
    name: 'detectObjectsWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      F√ºhrt die objekterkennung f√ºr das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
    name: endpoint
    fullName: endpoint
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'endpoint: string'
      return:
        type:
          - string
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
    name: 'generateThumbnail(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die H√∂he der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
    name: 'generateThumbnail(number, number, string, Object, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, options: Object, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
    name: 'generateThumbnail(number, number, string, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die H√∂he der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: Object, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
    name: 'generateThumbnailInStream(number, number, stream.Readable, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
    name: 'generateThumbnailInStreamWithHttpOperationResponse(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die H√∂he der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
    name: 'generateThumbnailWithHttpOperationResponse(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und H√∂he. Standardm√§√üig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten f√ºr den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverh√§ltnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enth√§lt die Bin√§rdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die H√∂he der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
    name: 'getAreaOfInterest(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterest(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
    name: 'getAreaOfInterest(string, Object, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterest(url: string, options: Object, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
    name: 'getAreaOfInterest(string, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterest(url: string, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
    name: 'getAreaOfInterestInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
    name: 'getAreaOfInterestInStream(stream.Readable, Object, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, options: Object, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
    name: 'getAreaOfInterestInStream(stream.Readable, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
    name: 'getAreaOfInterestInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
    name: 'getAreaOfInterestWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zur√ºck.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, enth√§lt die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zur√ºckgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getPackageJsonInfo
    name: getPackageJsonInfo(string)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Versucht, "Package.JSON" f√ºr das angegebene Azure Node.js-Paket zu suchen.
      Wenn gefunden wird, gibt die Namen und Version des Pakets durch Lesen der Datei "Package.JSON", wenn "Package.JSON" nicht gefunden wird, gibt einen Standardwert zur√ºck.
    syntax:
      content: 'function getPackageJsonInfo(managementClientDir: string)'
      parameters:
        - id: managementClientDir
          type:
            - string
          description: √ºbergeben Sie das Verzeichnis des spezifischen Azure-Management-Clients.
      return:
        type:
          - Object
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
    name: 'getReadOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei f√ºr die Read-Schnittstelle zur√ºckgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID der Lesevorgang in der Antwort der "Batch-Read-File"-Schnittstelle zur√ºckgegeben.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
    name: 'getReadOperationResult(string, Object, ServiceCallback<ReadOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei f√ºr die Read-Schnittstelle zur√ºckgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResult(operationId: string, options: Object, callback: ServiceCallback<ReadOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
    name: 'getReadOperationResult(string, ServiceCallback<ReadOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei f√ºr die Read-Schnittstelle zur√ºckgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResult(operationId: string, callback: ServiceCallback<ReadOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
    name: 'getReadOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei f√ºr die Read-Schnittstelle zur√ºckgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID der Lesevorgang in der Antwort der "Batch-Read-File"-Schnittstelle zur√ºckgegeben.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
    name: 'getTextOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, f√ºr das Ergebnis des Vorgangs Text abrufen. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zur√ºckgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID des textvorgangs zur√ºckgegeben werden, in die Antwort der Erkennung von Text
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
    name: 'getTextOperationResult(string, Object, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, f√ºr das Ergebnis des Vorgangs Text abrufen. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zur√ºckgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResult(operationId: string, options: Object, callback: ServiceCallback<TextOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
    name: 'getTextOperationResult(string, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, f√ºr das Ergebnis des Vorgangs Text abrufen. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zur√ºckgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
    name: 'getTextOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, f√ºr das Ergebnis des Vorgangs Text abrufen. Die URL f√ºr diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zur√ºckgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID des textvorgangs zur√ºckgegeben werden, in die Antwort der Erkennung von Text
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels
    name: listModels(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste dom√§nenspezifischer Modelle zur√ºck, die von der Maschinelles Sehen-API unterst√ºtzt werden. Zurzeit unterst√ºtzt die API folgende dom√§nenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehensw√ºrdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModels(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
    name: 'listModels(Object, ServiceCallback<ListModelsResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste dom√§nenspezifischer Modelle zur√ºck, die von der Maschinelles Sehen-API unterst√ºtzt werden. Zurzeit unterst√ºtzt die API folgende dom√§nenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehensw√ºrdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModels(options: Object, callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
    name: listModels(ServiceCallback<ListModelsResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste dom√§nenspezifischer Modelle zur√ºck, die von der Maschinelles Sehen-API unterst√ºtzt werden. Zurzeit unterst√ºtzt die API folgende dom√§nenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehensw√ºrdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
    name: listModelsWithHttpOperationResponse(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste dom√§nenspezifischer Modelle zur√ºck, die von der Maschinelles Sehen-API unterst√ºtzt werden. Zurzeit unterst√ºtzt die API folgende dom√§nenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehensw√ºrdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModelsWithHttpOperationResponse(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
    name: 'recognizePrintedText(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
    name: 'recognizePrintedText(boolean, string, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: Object, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
    name: 'recognizePrintedText(boolean, string, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: Object, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
    name: 'recognizePrintedTextInStreamWithHttpOperationResponse(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
    name: 'recognizePrintedTextWithHttpOperationResponse(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausf√ºhrung werden die OCR-Ergebnisse zur√ºckgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zur√ºckgegeben. Der Fehlercode m√∂glich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
    name: 'recognizeText(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
    name: 'recognizeText(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
    name: 'recognizeText(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
    name: 'recognizeTextInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
    name: 'recognizeTextInStream(stream.Readable, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
    name: 'recognizeTextInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
    name: 'recognizeTextInStreamWithHttpOperationResponse(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
    name: 'recognizeTextWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enth√§lt die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enth√§lt die URL, die Sie f√ºr Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden m√ºssen.'
    syntax:
      content: 'function recognizeTextWithHttpOperationResponse(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. M√∂gliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest_1
    name: sendRequest(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequest<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
      return:
        type:
          - Promise<TResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest
    name: 'sendRequest(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions, ServiceCallback<TResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequest<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions, callback: ServiceCallback<TResult>)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
        - id: callback
          type:
            - ServiceCallback<TResult>
          description: ''
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequestWithHttpOperationResponse
    name: sendRequestWithHttpOperationResponse(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequestWithHttpOperationResponse<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
      return:
        type:
          - Promise<HttpOperationResponse<TResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
    name: 'tagImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
    name: 'tagImage(string, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImage(url: string, options: Object, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
    name: 'tagImage(string, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
    name: 'tagImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
    name: 'tagImageInStream(stream.Readable, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
    name: 'tagImageInStream(stream.Readable, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
    name: 'tagImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    name: 'tagImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von W√∂rtern oder Tags, die f√ºr den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zur√ºckgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags k√∂nnen Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden ‚Äì zwei Eingabemethoden unterst√ºtzt.
      Eine erfolgreiche Antwort wird im JSON-Format zur√ºckgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            √ñffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
references:
  - uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    name: DomainModelResults>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>>'
        fullName: '>>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    name: ImageAnalysis>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    name: ImageDescription>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    name: DetectResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    name: AreaOfInterestResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    name: ReadOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    name: TextOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    name: ListModelsResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    name: OcrResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    name: TagResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>>'
        fullName: '>>'