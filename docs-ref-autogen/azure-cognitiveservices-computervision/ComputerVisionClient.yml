### YamlMime:UniversalReference
items:
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient
    name: ComputerVisionClient
    fullName: ComputerVisionClient
    children:
      - azure-cognitiveservices-computervision.ComputerVisionClient.addUserAgentInfo
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.constructor
      - azure-cognitiveservices-computervision.ComputerVisionClient.credentials
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getPackageJsonInfo
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequestWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    langs:
      - typeScript
    type: class
    summary: ''
    extends:
      name: ServiceClient
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.addUserAgentInfo
    name: addUserAgentInfo(any)
    children: []
    type: method
    langs:
      - typeScript
    summary: Benutzer-Agent-Header mit benutzerdefinierten Informationen hinzugefügt
    syntax:
      content: 'function addUserAgentInfo(additionalUserAgentInfo: any)'
      parameters:
        - id: additionalUserAgentInfo
          type:
            - any
          description: |
            Informationen, die Benutzer-Agent-Header, die als Zeichenfolge hinzugefügt werden.
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
    name: 'analyzeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
    name: 'analyzeImage(string, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImage(url: string, options: Object, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
    name: 'analyzeImage(string, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
    name: 'analyzeImageByDomain(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der domänenspezifischen, zu erkennen.
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
    name: 'analyzeImageByDomain(string, string, Object, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, options: Object, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
    name: 'analyzeImageByDomain(string, string, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der domänenspezifischen, zu erkennen.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: Object, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
    name: 'analyzeImageByDomainInStream(string, stream.Readable, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
    name: 'analyzeImageByDomainInStreamWithHttpOperationResponse(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der domänenspezifischen, zu erkennen.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
    name: 'analyzeImageByDomainWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang erkennt Inhalte in einem Bild durch Anwenden eines domänenspezifischen Modells. Die Liste domänenspezifischer Modelle, die von der Maschinelles Sehen-API unterstützt werden, kann über die /models-GET-Anforderung abgerufen werden.
      Zurzeit bietet die API folgende domänenspezifische Modelle: celebrities (Prominente), landmarks (Sehenswürdigkeiten).
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.
      Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Der Inhalt der domänenspezifischen, zu erkennen.
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
    name: 'analyzeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
    name: 'analyzeImageInStream(stream.Readable, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
    name: 'analyzeImageInStream(stream.Readable, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
    name: 'analyzeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
    name: 'analyzeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird ein umfangreicher Satz von Visualfeatures basierend auf dem Bildinhalt extrahiert.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden. Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
    name: 'batchReadFile(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden müssen.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
    name: 'batchReadFile(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden müssen.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
    name: 'batchReadFile(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden müssen.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
    name: 'batchReadFileInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enthält die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enthält die URL, die Sie, für die "Abrufen Ihrer Lesen der Ergebnisse verwenden müssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
    name: 'batchReadFileInStream(stream.Readable, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enthält die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enthält die URL, die Sie, für die "Abrufen Ihrer Lesen der Ergebnisse verwenden müssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
    name: 'batchReadFileInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enthält die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enthält die URL, die Sie, für die "Abrufen Ihrer Lesen der Ergebnisse verwenden müssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
    name: 'batchReadFileInStreamWithHttpOperationResponse(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis eines Dokument lesen-Vorgangs, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig Dokumenten optimiert. Wenn Sie die Read-Document Interface verwenden, enthält die Antwort ein Feld namens "Operation-Location". Der "Operation-Location"-Feld enthält die URL, die Sie, für die "Abrufen Ihrer Lesen der Ergebnisse verwenden müssen" mit Access OCR-Ergebnisse.'
    syntax:
      content: 'function batchReadFileInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
    name: 'batchReadFileWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Verwenden Sie diese Schnittstelle, um das Ergebnis von einem Lesevorgang, verwenden die Stand der Technik optische Zeichenerkennung (OCR) Algorithmen für textlastig-Dokumente optimiert. Wenn Sie die Datei lesen-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihr Vorgang "Lesen-Vorgangsergebnis" ergebniszugriff OCR verwenden müssen.'
    syntax:
      content: 'function batchReadFileWithHttpOperationResponse(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.constructor
    name: 'ComputerVisionClient(ServiceClientCredentials, string, ServiceClientOptions)'
    children: []
    type: constructor
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'new ComputerVisionClient(credentials: ServiceClientCredentials, endpoint: string, options?: ServiceClientOptions)'
      parameters:
        - id: credentials
          type:
            - ServiceClientCredentials
          description: |
            Abonnementanmeldeinformationen, die clientabonnement eindeutig identifiziert.
        - id: endpoint
          type:
            - string
          description: |
            Cognitive Services-Endpunkte unterstützt.
        - id: options
          type:
            - ServiceClientOptions
          description: ''
          optional: true
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.credentials
    name: credentials
    fullName: credentials
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'credentials: ServiceClientCredentials'
      return:
        type:
          - ServiceClientCredentials
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
    name: 'describeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
    name: 'describeImage(string, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImage(url: string, options: Object, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
    name: 'describeImage(string, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
    name: 'describeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
    name: 'describeImageInStream(stream.Readable, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
    name: 'describeImageInStream(stream.Readable, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
    name: 'describeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
    name: 'describeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Durch diesen Vorgang wird eine Beschreibung eines Bilds mit vollständigen Sätzen in verständlicher Sprache generiert. Die Beschreibung basiert auf einer Sammlung von Inhaltstags, die ebenfalls vom Vorgang zurückgegeben werden. Für jedes Bild können mehrere Beschreibungen generiert werden. Beschreibungen werden nach Zuverlässigkeitsbewertung sortiert. Alle Beschreibungen werden in englischer Sprache verfasst.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function describeImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
    name: 'detectObjects(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjects(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
    name: 'detectObjects(string, Object, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjects(url: string, options: Object, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
    name: 'detectObjects(string, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjects(url: string, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
    name: 'detectObjectsInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
    name: 'detectObjectsInStream(stream.Readable, Object, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, options: Object, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
    name: 'detectObjectsInStream(stream.Readable, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
    name: 'detectObjectsInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
    name: 'detectObjectsWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Führt die objekterkennung für das angegebene Bild.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function detectObjectsWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
    name: endpoint
    fullName: endpoint
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'endpoint: string'
      return:
        type:
          - string
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
    name: 'generateThumbnail(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die Höhe der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
    name: 'generateThumbnail(number, number, string, Object, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, options: Object, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
    name: 'generateThumbnail(number, number, string, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die Höhe der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: Object, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
    name: 'generateThumbnailInStream(number, number, stream.Readable, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
    name: 'generateThumbnailInStreamWithHttpOperationResponse(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die Höhe der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
    name: 'generateThumbnailWithHttpOperationResponse(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Miniaturansicht mit der vom Benutzer angegebenen Breite und Höhe. Standardmäßig analysiert der Dienst das Bild, identifiziert den Bereich, der von Interesse ist (Region of Interest, ROI), und generiert basierend auf dem ROI intelligente Koordinaten für den Zuschnitt.
      Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet.
      Eine erfolgreiche Antwort enthält die Binärdaten zur Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Breite der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: height
          type:
            - number
          description: |
            Die Höhe der Miniaturansicht in Pixel. Es muss zwischen 1 und 1.024 sein. Empfohlene Mindestanzahl von 50.
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
    name: 'getAreaOfInterest(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterest(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
    name: 'getAreaOfInterest(string, Object, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterest(url: string, options: Object, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
    name: 'getAreaOfInterest(string, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterest(url: string, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
    name: 'getAreaOfInterestInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
    name: 'getAreaOfInterestInStream(stream.Readable, Object, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, options: Object, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
    name: 'getAreaOfInterestInStream(stream.Readable, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
    name: 'getAreaOfInterestInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
    name: 'getAreaOfInterestWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt einen Begrenzungsrahmen um den wichtigsten Bereich des Bilds zurück.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
      Bei einem Fehler werden den Fehlercode und eine Fehlermeldung zurückgegeben. Der Fehlercode konnte InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeouts oder InternalServerError sein.
    syntax:
      content: 'function getAreaOfInterestWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getPackageJsonInfo
    name: getPackageJsonInfo(string)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Versucht, "Package.JSON" für das angegebene Azure Node.js-Paket zu suchen.
      Wenn gefunden wird, gibt die Namen und Version des Pakets durch Lesen der Datei "Package.JSON", wenn "Package.JSON" nicht gefunden wird, gibt einen Standardwert zurück.
    syntax:
      content: 'function getPackageJsonInfo(managementClientDir: string)'
      parameters:
        - id: managementClientDir
          type:
            - string
          description: übergeben Sie das Verzeichnis des spezifischen Azure-Management-Clients.
      return:
        type:
          - Object
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
    name: 'getReadOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei für die Read-Schnittstelle zurückgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID der Lesevorgang in der Antwort der "Batch-Read-File"-Schnittstelle zurückgegeben.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
    name: 'getReadOperationResult(string, Object, ServiceCallback<ReadOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei für die Read-Schnittstelle zurückgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResult(operationId: string, options: Object, callback: ServiceCallback<ReadOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
    name: 'getReadOperationResult(string, ServiceCallback<ReadOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei für die Read-Schnittstelle zurückgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResult(operationId: string, callback: ServiceCallback<ReadOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
    name: 'getReadOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, zum Abrufen von OCR-Ergebnisse der Read-Vorgang. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Batchdatei für die Read-Schnittstelle zurückgegebenen abgerufen werden soll.'
    syntax:
      content: 'function getReadOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID der Lesevorgang in der Antwort der "Batch-Read-File"-Schnittstelle zurückgegeben.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
    name: 'getTextOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID des textvorgangs zurückgegeben werden, in die Antwort der Erkennung von Text
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
    name: 'getTextOperationResult(string, Object, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResult(operationId: string, options: Object, callback: ServiceCallback<TextOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
    name: 'getTextOperationResult(string, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
    name: 'getTextOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.'
    syntax:
      content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID des textvorgangs zurückgegeben werden, in die Antwort der Erkennung von Text
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels
    name: listModels(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste domänenspezifischer Modelle zurück, die von der Maschinelles Sehen-API unterstützt werden. Zurzeit unterstützt die API folgende domänenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehenswürdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModels(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
    name: 'listModels(Object, ServiceCallback<ListModelsResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste domänenspezifischer Modelle zurück, die von der Maschinelles Sehen-API unterstützt werden. Zurzeit unterstützt die API folgende domänenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehenswürdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModels(options: Object, callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
    name: listModels(ServiceCallback<ListModelsResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste domänenspezifischer Modelle zurück, die von der Maschinelles Sehen-API unterstützt werden. Zurzeit unterstützt die API folgende domänenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehenswürdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
    name: listModelsWithHttpOperationResponse(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang gibt die Liste domänenspezifischer Modelle zurück, die von der Maschinelles Sehen-API unterstützt werden. Zurzeit unterstützt die API folgende domänenspezifische Modelle: celebrity recognizer (Prominentenerkennung), landmark recognizer (Sehenswürdigkeitenerkennung).
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function listModelsWithHttpOperationResponse(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
    name: 'recognizePrintedText(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
    name: 'recognizePrintedText(boolean, string, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: Object, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
    name: 'recognizePrintedText(boolean, string, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: Object, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
    name: 'recognizePrintedTextInStreamWithHttpOperationResponse(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
    name: 'recognizePrintedTextWithHttpOperationResponse(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Optische Zeichenerkennung (OCR) erkennt Text in einem Bild und extrahiert die erkannten Zeichen in eine vom Computer verwendbare Zeichenfolge.
      Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden.
      Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
    syntax:
      content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
    name: 'recognizeText(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
    name: 'recognizeText(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
    name: 'recognizeText(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
    name: 'recognizeTextInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
    name: 'recognizeTextInStream(stream.Readable, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
    name: 'recognizeTextInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
    name: 'recognizeTextInStreamWithHttpOperationResponse(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
    name: 'recognizeTextWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste erkennt Text Vorgangsergebnis-Vorgang verwenden müssen.'
    syntax:
      content: 'function recognizeTextWithHttpOperationResponse(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: mode
          type:
            - string
          description: |
            Der Typ des Texts erkannt. Mögliche Werte sind: 'Handwritten', 'Printed'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest_1
    name: sendRequest(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequest<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
      return:
        type:
          - Promise<TResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest
    name: 'sendRequest(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions, ServiceCallback<TResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequest<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions, callback: ServiceCallback<TResult>)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
        - id: callback
          type:
            - ServiceCallback<TResult>
          description: ''
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequestWithHttpOperationResponse
    name: sendRequestWithHttpOperationResponse(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequestWithHttpOperationResponse<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
      return:
        type:
          - Promise<HttpOperationResponse<TResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
    name: 'tagImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
    name: 'tagImage(string, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImage(url: string, options: Object, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
    name: 'tagImage(string, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
    name: 'tagImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
    name: 'tagImageInStream(stream.Readable, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
    name: 'tagImageInStream(stream.Readable, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
    name: 'tagImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Ein Bild-Stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    name: 'tagImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Die Maschinelles Sehen-API kann Tags basierend auf Objekten, Lebewesen, Landschaften oder Aktionen zurückgegeben, die in Bildern ermittelt werden. Im Gegensatz zu Kategorien werden Tags nicht anhand eines hierarchischen Klassifizierungssystems angeordnet, sondern entsprechen Bildinhalten. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle Tags werden in englischer Sprache angegeben.
      (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.
      Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben. Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
    syntax:
      content: 'function tagImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Öffentlich erreichbar URL eines Bilds.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
references:
  - uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    name: DomainModelResults>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>>'
        fullName: '>>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    name: ImageAnalysis>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    name: ImageDescription>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    name: DetectResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    name: AreaOfInterestResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    name: ReadOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    name: TextOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    name: ListModelsResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    name: OcrResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    name: TagResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>>'
        fullName: '>>'