### YamlMime:UniversalReference
ms.openlocfilehash: 496552af79989c144ce96db561de8b0882be0c21
ms.sourcegitcommit: 87f95d58ec8de16e115bc344efeb084afc346b74
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 08/12/2018
ms.locfileid: "40060854"
items:
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient
  name: ComputerVisionAPIClient
  fullName: ComputerVisionAPIClient
  children:
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
  langs:
  - typeScript
  type: class
  summary: ''
  extends:
    name: ServiceClient
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.  In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden.  Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
  syntax:
    content: 'function analyzeImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.  In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden.  Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
  syntax:
    content: 'function analyzeImage(url: string, options: function, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.  In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden.  Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
  syntax:
    content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Der Inhalt der domänenspezifischen, zu erkennen. Folgende Werte sind möglich: 'Prominente', "Orientierungspunkte"
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options: function, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Der Inhalt der domänenspezifischen, zu erkennen.
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: function, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  name: analyzeImageByDomainInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Der Inhalt der domänenspezifischen, zu erkennen.
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
  name: analyzeImageByDomainWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang erkennt Inhalt in einem Image von einem domänenspezifischen Modell anwenden.  Die Liste der Modelle, die durch das Computer Vision-API unterstützt werden, kann mithilfe der/Models-GET-Anforderung abgerufen werden.  Die API bietet derzeit nur ein einzelnes Modell für die domänenspezifischen: berühmtheiten. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.

    Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Der Inhalt der domänenspezifischen, zu erkennen. Folgende Werte sind möglich: 'Prominente', "Orientierungspunkte"
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
  name: analyzeImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features.
  syntax:
    content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
  name: analyzeImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang extrahiert eine Vielzahl von visuellen basierend auf den Inhalt des Features. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt.  In Ihre Anforderung ist ein optionaler Parameter können Sie auswählen, welche Funktionen zum Zurückgeben vorhanden.  Standardmäßig werden die Image-Kategorien in der Antwort zurückgegeben.
  syntax:
    content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
  name: azureRegion
  fullName: azureRegion
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'azureRegion: string'
    return:
      type:
      - string
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
  name: ComputerVisionAPIClient
  children: []
  type: constructor
  langs:
  - typeScript
  summary: ''
  syntax:
    content: 'new ComputerVisionAPIClient(credentials: ServiceClientCredentials, azureRegion: string, options?: ServiceClientOptions)'
    parameters:
    - id: credentials
      type:
      - ServiceClientCredentials
      description: >
        Abonnementanmeldeinformationen, die clientabonnement eindeutig identifiziert.
    - id: azureRegion
      type:
      - string
      description: >
        Azure-Regionen unterstützt für Cognitive Services-Endpunkte. Folgende Werte sind möglich: "USA, Westen", "Europa, Westen", "Southeastasia", "eastus2", "Westcentralus", "westus2", "USA, Osten", "Southcentralus", "Northeurope", "Asien, Osten", "Australiaeast", "Brazilsouth"
    - id: options
      type:
      - ServiceClientOptions
      description: ''
      optional: true
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
  name: credentials
  fullName: credentials
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'credentials: ServiceClientCredentials'
    return:
      type:
      - ServiceClientCredentials
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImage(url: string, options: function, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
  name: describeImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
  name: describeImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Diesem Vorgang wird eine Beschreibung eines Bilds in mit vollständigen Sätzen für Menschen lesbarer Sprache generiert.  Die Beschreibung basieren auf eine Auflistung von Content-Tags, die auch vom Vorgang zurückgegeben werden. Mehr als eine Beschreibung kann für jedes Bild generiert werden.  Beschreibungen sind nach ihrer vertrauensergebnis sortiert. Alle Beschreibungen werden in englischer Sprache. (1) Wenn Sie ein Image hochladen, oder (2) eine Bild-URL angeben werden – zwei Eingabemethoden unterstützt. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.
  syntax:
    content: 'function describeImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options: function, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Die Breite der Miniaturansicht. Es muss zwischen 1 und 1.024 sein.

        Empfohlene Mindestanzahl von 50.
    - id: height
      type:
      - number
      description: >
        Die Höhe der Miniaturansicht. Es muss zwischen 1 und

        1024. Empfohlene Mindestanzahl von 50.
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Die Breite der Miniaturansicht. Es muss zwischen 1 und 1.024 sein.

        Empfohlene Mindestanzahl von 50.
    - id: height
      type:
      - number
      description: >
        Die Höhe der Miniaturansicht. Es muss zwischen 1 und

        1024. Empfohlene Mindestanzahl von 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: function, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
  name: generateThumbnailInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Die Breite der Miniaturansicht. Es muss zwischen 1 und 1.024 sein.

        Empfohlene Mindestanzahl von 50.
    - id: height
      type:
      - number
      description: >
        Die Höhe der Miniaturansicht. Es muss zwischen 1 und

        1024. Empfohlene Mindestanzahl von 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
  name: generateThumbnailWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Dieser Vorgang wird eine Miniaturansicht mit der Benutzer angegebenen Breite und Höhe generiert. Der Dienst standardmäßig analysiert das Bild, identifiziert die Region von Interesse sind (ROI) und intelligente Zuschneiden Koordinaten, die basierend auf den ROI generiert.

    Intelligentes Zuschneiden kann, wenn Sie ein Seitenverhältnis angeben, die von der Eingabebilds unterscheidet. Eine erfolgreiche Antwort enthält die binäre Miniaturansicht. Wenn die Anforderung fehlgeschlagen ist, enthält die Antwort einen Fehlercode und eine Nachricht ein, um zu ermitteln, welche Fehler aufgetreten sind.
  syntax:
    content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Die Breite der Miniaturansicht. Es muss zwischen 1 und 1.024 sein.

        Empfohlene Mindestanzahl von 50.
    - id: height
      type:
      - number
      description: >
        Die Höhe der Miniaturansicht. Es muss zwischen 1 und

        1024. Empfohlene Mindestanzahl von 50.
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options?: function)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID des textvorgangs zurückgegeben werden, in die Antwort der Erkennung von handschriftlichen Text
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options: function, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.
  syntax:
    content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
  name: getTextOperationResultWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Diese Schnittstelle wird verwendet, für das Ergebnis des Vorgangs Text abrufen. Die URL für diese Schnittstelle, die aus "Operation-Location"-Feld aus der Erkennung von Text-Schnittstelle zurückgegeben abgerufen werden soll.
  syntax:
    content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: function)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID des textvorgangs zurückgegeben werden, in die Antwort der Erkennung von handschriftlichen Text
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Dieser Vorgang gibt die Liste der Modelle, die durch das Computer Vision-API unterstützt werden.  Die API unterstützt derzeit nur einem domänenspezifischen Modell: eine Erkennung berühmter Personen. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.'
  syntax:
    content: 'function listModels(options?: function)'
    parameters:
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Dieser Vorgang gibt die Liste der Modelle, die durch das Computer Vision-API unterstützt werden.  Die API unterstützt derzeit nur einem domänenspezifischen Modell: eine Erkennung berühmter Personen. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.'
  syntax:
    content: 'function listModels(options: function, callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Dieser Vorgang gibt die Liste der Modelle, die durch das Computer Vision-API unterstützt werden.  Die API unterstützt derzeit nur einem domänenspezifischen Modell: eine Erkennung berühmter Personen. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.'
  syntax:
    content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
  name: listModelsWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Dieser Vorgang gibt die Liste der Modelle, die durch das Computer Vision-API unterstützt werden.  Die API unterstützt derzeit nur einem domänenspezifischen Modell: eine Erkennung berühmter Personen. Eine erfolgreiche Antwort wird im JSON-Format zurückgegeben.  Wenn die Anforderung fehlgeschlagen ist, wird die Antwort enthalten, einem Fehlercode und eine Nachricht, um zu verstehen, welche Fehler aufgetreten sind.'
  syntax:
    content: 'function listModelsWithHttpOperationResponse(options?: function)'
    parameters:
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: function, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: function, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
  name: recognizePrintedTextInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
  name: recognizePrintedTextWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Optische Zeichenerkennung (OCR) erkennt gedruckten Text in einem Bild und extrahiert die erkannten Zeichen in eine computerlesbare Zeichenfolge.

    Bei erfolgreicher Ausführung werden die OCR-Ergebnisse zurückgegeben werden. Bei einem Fehler wird der Fehlercode sowie eine Fehlermeldung zurückgegeben. Der Fehlercode möglich InvalidImageUrl InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage oder InternalServerError.
  syntax:
    content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Erkennen Sie, ob die Ausrichtung von Text in der Abbildung. Mit der DetectOrientation = "true", die OCR-Dienst versucht, die Ausrichtung des Bilds zu erkennen und korrigieren Sie dies vor der weiteren Verarbeitung (z. B. Wenn sie nach unten zeigende ist).
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeText(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeText(url: string, options: function, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeText(url: string, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, options: function, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
  name: recognizeTextInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
  name: recognizeTextWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Erkennen Sie Text-Vorgang. Wenn Sie die Erkennung von-Schnittstelle verwenden, enthält die Antwort ein Feld namens "Operation-Location". Das Feld "Operation-Location" enthält die URL, die Sie für Ihre erste handschriftlichen Text Vorgangsergebnis-Vorgang verwenden müssen.
  syntax:
    content: 'function recognizeTextWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImage(url: string, options: function, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
  name: tagImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Ein Bild-Stream.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
  name: tagImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Dieser Vorgang generiert eine Liste von Wörtern oder Tags, die für den Inhalt des angegebenen Bilds relevant sind. Das Computer Vision-API können Objekte, Tags anhand Leben ab, Landschaften oder Aktionen im Images zurückgegeben. Im Gegensatz zu Kategorien Tags sind nicht anhand einer hierarchischen Klassifizierungssystem angeordnet, aber Bildinhalt entsprechen. Tags können Hinweise, um Mehrdeutigkeiten zu vermeiden, oder geben Sie Kontext enthalten, zum Beispiel kann das Tag "Cello" mit der Hinweis "Musikinstrument" keiner. Alle RFID-Transponder sind in Englisch verfügbar.
  syntax:
    content: 'function tagImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
references:
- uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>>'
    fullName: '>>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.OcrResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TagResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>>'
    fullName: '>>'
